---
title: "Keras on Reuters data"
output: html_notebook
---

## Keras

Keras is a high-level neural networks API developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research. Keras has the following key features:

* Allows the same code to run on CPU or on GPU, seamlessly.
* User-friendly API which makes it easy to quickly prototype deep learning models.
* Built-in support for convolutional networks (for computer vision), recurrent networks (for sequence processing), and any combination of both.

Supports arbitrary network architectures: multi-input or multi-output models, layer sharing, model sharing, etc. This means that Keras is appropriate for building essentially any deep learning model, from a memory network to a neural Turing machine.

This website provides documentation for the R interface to Keras. See the main Keras website at [keras.io](https://keras.io) for additional information on the project.

## Install

The [R interface to Keras](https://rstudio.github.io/keras/index.html) uses TensorFlow™ as it’s default tensor backend engine. To get started you should therefore install both the keras R package and the TensorFlow engine.

First, install the keras [R package](https://github.com/rstudio/keras) from GitHub as follows:

```{r eval=FALSE}
devtools::install_github("rstudio/keras")
keras::install_tensorflow()
```

This will provide you with a default installation of TensorFlow suitable for use with the keras R package. See the article on TensorFlow installation to learn about more advanced options, including installing a version of TensorFlow that takes advantage of Nvidia GPUs if you have the correct CUDA libraries installed.

## Setup

Load the Keras package and set the initial values that will be used by the Keras model.

```{r}
library(keras)
max_words <- 1000 # Top n most popular words to analyze
batch_size <- 32 # Number of samples per gradient update
epochs <- 5 # Number of times to iterate over the training data arrays
```

## Load data

These data from [Reuters](http://www.daviddlewis.com/resources/testcollections/reuters21578/) include 11,228 newswires from Reuters, labeled over 46 topics. These data were pulled from the (Keras documentation)[https://keras.io/datasets/#reuters-newswire-topics-classification].

```{r}
reuters <- dataset_reuters(num_words = max_words, test_split = 0.2)

x_train <- reuters$train$x
y_train <- reuters$train$y
x_test <- reuters$test$x
y_test <- reuters$test$y

length(x_train)
length(x_test)
```

## Vectorizing sequence data

Vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf.

```{r}
tokenizer <- text_tokenizer(num_words = max_words)

x_train <- sequences_to_matrix(tokenizer, x_train, mode = 'binary')
dim(x_train)

x_test <- sequences_to_matrix(tokenizer, x_test, mode = 'binary')
dim(x_test)

num_classes <- max(y_train) + 1
num_classes
```

## Create class matrix

Convert class vector to binary class matrix for use with categorical_crossentropy.

```{r}
y_train <- to_categorical(y_train, num_classes)
y_test <- to_categorical(y_test, num_classes)
dim(y_train)
dim(y_test)
```

## Building model

The core data structure of Keras is a model, a way to organize layers. The simplest type of model is the Sequential model, a linear stack of layers. For more complex architectures, you should use the Keras functional API, which allows to build arbitrary graphs of layers.

```{r}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 512, input_shape = c(max_words)) %>%
  layer_activation(activation = 'relu') %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = num_classes) %>%
  layer_activation(activation = 'softmax')

model %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = 'adam',
  metrics = c('accuracy')
)

history <- model %>% fit(
  x_train, y_train,
  batch_size = batch_size,
  epochs = epochs,
  verbose = 1,
  validation_split = 0.1
)

score <- model %>% evaluate(
  x_test, y_test,
  batch_size = batch_size,
  verbose = 1
)

cat('Test score:', score[[1]], '\n')
cat('Test accuracy', score[[2]], '\n')
```

## Predict

```{r}
pred <- model %>% predict_classes(
  x_test,
  batch_size = batch_size,
  verbose = 1
)

actual <- reuters$test$y

table(pred, actual)
```

